{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LDA and LLMs for Document Summarization"
      ],
      "metadata": {
        "id": "KYNx8LFq59Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing necessary libraries not included in colab."
      ],
      "metadata": {
        "id": "rqI8qrJc6PvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf==3.14.0\n",
        "!pip install tiktoken==0.4.0\n",
        "!pip install langchain==0.0.353\n",
        "!pip install openai==0.27.8\n",
        "!pip install gdown==4.7.3\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZO1J-US5fCT",
        "outputId": "68bc858c-701b-44ea-f1b3-6a0e3fa65128"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf==3.14.0 in /usr/local/lib/python3.10/dist-packages (3.14.0)\n",
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2024.2.2)\n",
            "Requirement already satisfied: langchain==0.0.353 in /usr/local/lib/python3.10/dist-packages (0.0.353)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (0.0.20)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.353) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.353) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.353) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.353) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.353) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.353) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.353) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.353) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.353) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.4->langchain==0.0.353) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.4->langchain==0.0.353) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.353) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.353) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.353) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.353) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.353) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.353) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.353) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.353) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.4->langchain==0.0.353) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.4->langchain==0.0.353) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.353) (1.0.0)\n",
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Requirement already satisfied: gdown==4.7.3 in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.3) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.3) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.3) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.3) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.3) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.7.3) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.3) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.3) (1.7.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hnuarluthuAE"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import nltk\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from pypdf import PdfReader\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions\n",
        "\n",
        "The following are the functions that implement the prepocessing, topic extraction, and LLM call."
      ],
      "metadata": {
        "id": "06VdMKxu8Mie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, stop_words):\n",
        "    \"\"\"\n",
        "    Tokenizes and preprocesses the input text, removing stopwords and short\n",
        "    tokens.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input text to preprocess.\n",
        "        stop_words (set): A set of stopwords to be removed from the text.\n",
        "    Returns:\n",
        "        list: A list of preprocessed tokens.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for token in simple_preprocess(text, deacc=True):\n",
        "        if token not in stop_words and len(token) > 3:\n",
        "            result.append(token)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "sfdeuTP3zlEi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_topic_lists_from_pdf(file, num_topics, words_per_topic):\n",
        "    \"\"\"\n",
        "    Extracts topics and their associated words from a PDF document using the\n",
        "    Latent Dirichlet Allocation (LDA) algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        file (str): The path to the PDF file for topic extraction.\n",
        "        num_topics (int): The number of topics to discover.\n",
        "        words_per_topic (int): The number of words to include per topic.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of num_topics sublists, each containing relevant words\n",
        "        for a topic.\n",
        "    \"\"\"\n",
        "    # Load the pdf file\n",
        "    loader = PdfReader(file)\n",
        "\n",
        "    # Extract the text from each page into a list. Each page is considered a document\n",
        "    documents= []\n",
        "    for page in loader.pages:\n",
        "        documents.append(page.extract_text())\n",
        "\n",
        "    # Preprocess the documents\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words(['english','spanish']))\n",
        "    processed_documents = [preprocess(doc, stop_words) for doc in documents]\n",
        "\n",
        "    # Create a dictionary and a corpus\n",
        "    dictionary = corpora.Dictionary(processed_documents)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
        "\n",
        "    # Build the LDA model\n",
        "    lda_model = LdaModel(\n",
        "        corpus,\n",
        "        num_topics=num_topics,\n",
        "        id2word=dictionary,\n",
        "        passes=15\n",
        "        )\n",
        "\n",
        "    # Retrieve the topics and their corresponding words\n",
        "    topics = lda_model.print_topics(num_words=words_per_topic)\n",
        "\n",
        "    # Store each list of words from each topic into a list\n",
        "    topics_ls = []\n",
        "    for topic in topics:\n",
        "        words = topic[1].split(\"+\")\n",
        "        topic_words = [word.split(\"*\")[1].replace('\"', '').strip() for word in words]\n",
        "        topics_ls.append(topic_words)\n",
        "\n",
        "    return topics_ls\n"
      ],
      "metadata": {
        "id": "8BXRZ_W1zmJX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topics_from_pdf(llm, file, num_topics, words_per_topic):\n",
        "    \"\"\"\n",
        "    Generates descriptive prompts for LLM based on topic words extracted from a\n",
        "    PDF document.\n",
        "\n",
        "    This function takes the output of `get_topic_lists_from_pdf` function,\n",
        "    which consists of a list of topic-related words for each topic, and\n",
        "    generates an output string in bulleted nested list format.\n",
        "\n",
        "    Parameters:\n",
        "        llm (LLM): An instance of the Large Language Model (LLM) for generating\n",
        "        responses.\n",
        "        file (str): The path to the PDF file for extracting topic-related words.\n",
        "        num_topics (int): The number of topics to consider.\n",
        "        words_per_topic (int): The number of words per topic to include.\n",
        "\n",
        "    Returns:\n",
        "        str: A response generated by the language model based on the provided\n",
        "        topic words.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract topics and convert them to string\n",
        "    list_of_topicwords = get_topic_lists_from_pdf(file, num_topics, words_per_topic)\n",
        "    string_lda = \"\"\n",
        "    for list in list_of_topicwords:\n",
        "        string_lda += str(list) + \"\\n\"\n",
        "\n",
        "    # Create the template\n",
        "    template_string = '''Describe the topic of each of the {num_topics}\n",
        "        double-quote delimited lists in a simple sentence and also write down\n",
        "        three possible different subthemes. The lists are the result of an\n",
        "        algorithm for topic discovery.\n",
        "        Do not provide an introduction or a conclusion, only describe the\n",
        "        topics. Do not mention the word \"topic\" when describing the topics.\n",
        "        Use the following template for the response.\n",
        "\n",
        "        1: <<<(sentence describing the topic)>>>\n",
        "        - <<<(Phrase describing the first subtheme)>>>\n",
        "        - <<<(Phrase describing the second subtheme)>>>\n",
        "        - <<<(Phrase describing the third subtheme)>>>\n",
        "\n",
        "        2: <<<(sentence describing the topic)>>>\n",
        "        - <<<(Phrase describing the first subtheme)>>>\n",
        "        - <<<(Phrase describing the second subtheme)>>>\n",
        "        - <<<(Phrase describing the third subtheme)>>>\n",
        "\n",
        "        ...\n",
        "\n",
        "        n: <<<(sentence describing the topic)>>>\n",
        "        - <<<(Phrase describing the first subtheme)>>>\n",
        "        - <<<(Phrase describing the second subtheme)>>>\n",
        "        - <<<(Phrase describing the third subtheme)>>>\n",
        "\n",
        "        Lists: \"\"\"{string_lda}\"\"\" '''\n",
        "\n",
        "    # LLM call\n",
        "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "    response = chain.run({\n",
        "        \"string_lda\" : string_lda,\n",
        "        \"num_topics\" : num_topics\n",
        "        })\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "mhgTvRHQzmGp",
        "outputId": "39ef640c-4b6b-41fd-ab10-3a99b56ce06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (<ipython-input-11-ffbf788611a9>, line 23)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-ffbf788611a9>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    list_of_topicwords = get_topic_lists_from_pdf(file = \"/content/Task1_Input.pdf\", num_topics, words_per_topic)\u001b[0m\n\u001b[0m                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API key\n",
        "\n",
        "For this demo, we are going to use chatgpt-3.5 Turbo. For that, it is necessary to introduce the API key. Check [How to get an OPEN API key for ChatGPT](https://www.maisieai.com/help/how-to-get-an-openai-api-key-for-chatgpt) for instructions on how to get one."
      ],
      "metadata": {
        "id": "_gIePRtyINYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key = \"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\"\n",
        "llm = OpenAI(openai_api_key=openai_key, max_tokens=-1)"
      ],
      "metadata": {
        "id": "zF-pM0cNIMqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b2fe65-9d66-4c68-808f-8d071bd8c0f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with documents\n",
        "\n",
        "Now, lets try with a public domain pdf document, The Metamorphosis By Franz Kafka (1915)."
      ],
      "metadata": {
        "id": "ypRlS4Ad8mkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1mpXUmuLGzkVEqsTicQvBPcpPJW0aPqdL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-QfH7Zm9Ci2",
        "outputId": "1baf8769-b101-4fe2-9f7d-a20e20aa025e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mpXUmuLGzkVEqsTicQvBPcpPJW0aPqdL\n",
            "To: /content/the-metamorphosis.pdf\n",
            "\r  0% 0.00/427k [00:00<?, ?B/s]\r100% 427k/427k [00:00<00:00, 47.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/Task1_Input.pdf\"\n",
        "\n",
        "num_topics = 6\n",
        "words_per_topic = 30\n",
        "\n",
        "summary = topics_from_pdf(llm, file, num_topics, words_per_topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUEsLb8t9Cc9",
        "outputId": "fa74caac-cf59-4ead-8297-58014d112611"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YA9M5bG-9CTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, let's try with a technical book: The Foundations of Geometry by David Hilbert (1899).\n"
      ],
      "metadata": {
        "id": "SfRzqVI7yOQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1T_FeuGsoC08U_6Xb8Awt50CJXBUqji4D\n",
        "\n",
        "file = \"/content/Task1_Input.pdf\"\n",
        "summary = topics_from_pdf(llm, file, num_topics, words_per_topic)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Do0XIP-yYBv",
        "outputId": "21d026be-2ce3-4bf0-f596-1b82265590da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T_FeuGsoC08U_6Xb8Awt50CJXBUqji4D\n",
            "To: /content/Hilbert.pdf\n",
            "\r  0% 0.00/878k [00:00<?, ?B/s]\r100% 878k/878k [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1: \"Loss\"\n",
            "- \"Property damage\"\n",
            "- \"Financial loss\"\n",
            "- \"Emotional loss\"\n",
            "\n",
            "2: \"Coverage\"\n",
            "- \"Liability coverage\"\n",
            "- \"Property coverage\"\n",
            "- \"Comprehensive coverage\"\n",
            "\n",
            "3: \"Revised\"\n",
            "- \"Updated laws and regulations\"\n",
            "- \"Changes in policy\"\n",
            "- \"Revised coverage options\"\n",
            "\n",
            "4: \"Settlement\"\n",
            "- \"Insurance claim settlement\"\n",
            "- \"Settlement agreement\"\n",
            "- \"Settlement negotiations\"\n",
            "\n",
            "5: \"Cost\"\n",
            "- \"Insurance cost\"\n",
            "- \"Repair cost\"\n",
            "- \"Replacement cost\"\n",
            "\n",
            "6: \"Structures\"\n",
            "- \"Home structures\"\n",
            "- \"Business structures\"\n",
            "- \"Coverage for structures\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free experiment with the **number of topics** and the number of **words per topic** and find the combination that works for your document."
      ],
      "metadata": {
        "id": "4HP3wg7wN-pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Licence\n",
        "\n",
        "GNU General Public License v2.0"
      ],
      "metadata": {
        "id": "ZHrtCfay8ieJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "\n",
        "[Antonio Jimenez](https://www.linkedin.com/in/antonio-jimnzc)"
      ],
      "metadata": {
        "id": "N5LxW1PgPTh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items = summary.split(\"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "fr4k812tbqEM"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(items)"
      ],
      "metadata": {
        "id": "ba8qhkYAbtKj",
        "outputId": "f7b671cc-9f8a-403b-a5d2-ed5a59308f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '1: \"Loss\"\\n- \"Property damage\"\\n- \"Financial loss\"\\n- \"Emotional loss\"', '2: \"Coverage\"\\n- \"Liability coverage\"\\n- \"Property coverage\"\\n- \"Comprehensive coverage\"', '3: \"Revised\"\\n- \"Updated laws and regulations\"\\n- \"Changes in policy\"\\n- \"Revised coverage options\"', '4: \"Settlement\"\\n- \"Insurance claim settlement\"\\n- \"Settlement agreement\"\\n- \"Settlement negotiations\"', '5: \"Cost\"\\n- \"Insurance cost\"\\n- \"Repair cost\"\\n- \"Replacement cost\"', '6: \"Structures\"\\n- \"Home structures\"\\n- \"Business structures\"\\n- \"Coverage for structures\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items[1]"
      ],
      "metadata": {
        "id": "Ast5Qgmzbuup",
        "outputId": "763cce08-ccca-4b3f-89b6-d5b56f6c0e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1: \"Loss\"\\n- \"Property damage\"\\n- \"Financial loss\"\\n- \"Emotional loss\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "d4h6inMOby3B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_reader = PdfReader('/content/Task1_Input.pdf')"
      ],
      "metadata": {
        "id": "axfo6sDncqxZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read data from the file and put them into a variable called raw_text\n",
        "\n",
        "raw_text = ''\n",
        "for i, page in enumerate (doc_reader.pages):\n",
        "  text = page.extract_text()\n",
        "  if text:\n",
        "    raw_text +=text"
      ],
      "metadata": {
        "id": "2K1m1yx2dCu8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "_20ZQ_9MdH9m"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting up the text into smaller chunks for indexing\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 400,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "J0aKpp2RdKuo"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "gz3jj0gEdmBx",
        "outputId": "ad30cdc9-9a21-4e3d-facb-b5acadb2d656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "Vp9dpitUfHiR"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "0JyNvH6VfWw1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key ='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'"
      ],
      "metadata": {
        "id": "5pR9nK7Zf649"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to use\n",
        "model_name_embedding = \"text-embedding-ada-002\"\n",
        "\n",
        "# Define the encode kwargs\n",
        "encode_kwargs = {\n",
        "    \"max_length\": 512,\n",
        "    \"truncation\": \"only_first\",\n",
        "}\n",
        "\n",
        "# Create the OpenAI embeddings instance\n",
        "model_norm = OpenAIEmbeddings(\n",
        "    model_name=model_name_embedding,\n",
        "    encode_kwargs=encode_kwargs,\n",
        "    openai_api_key = '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'\n",
        ")"
      ],
      "metadata": {
        "id": "MxPEPGPCdMg3",
        "outputId": "8351b3f3-3a5c-47e6-a42b-6d4492665568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py:268: UserWarning: WARNING! model_name is not default parameter.\n",
            "                    model_name was transferred to model_kwargs.\n",
            "                    Please confirm that model_name is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py:268: UserWarning: WARNING! encode_kwargs is not default parameter.\n",
            "                    encode_kwargs was transferred to model_kwargs.\n",
            "                    Please confirm that encode_kwargs is what you intended.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text"
      ],
      "metadata": {
        "id": "-mPP5vFGdO93"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
        "    #print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])\n"
      ],
      "metadata": {
        "id": "spKL_-cBeKAw"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "id": "Z7itWc7tg0He",
        "outputId": "9b52375e-026b-40ff-cb6f-f55fd1f835c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.3)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "34jcF8k4g_xR"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "persist_directory = 'db'\n",
        "\n",
        "## Here is the nmew embeddings being used\n",
        "embedding = model_norm\n",
        "\n",
        "vectordb = Chroma.from_texts(texts=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Bgwlb-7NeMDW"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to use\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Define the encode kwargs\n",
        "encode_kwargs = {\n",
        "    \"max_length\": 2048,  # Increase the max length to 2048\n",
        "    \"truncation\": \"only_first\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "qri69qTTgaiu"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "JsTF1pV1mVPs"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0,\n",
        "                 model=model_name,\n",
        "                 openai_api_key = \"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\",\n",
        "                 )"
      ],
      "metadata": {
        "id": "kp_WEVRqmO2U"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "persist_directory = 'db'\n",
        "\n",
        "## Here is the nmew embeddings being used\n",
        "embedding = model_norm\n",
        "\n",
        "vectordb = Chroma.from_texts(texts=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Ea0SBxlRiEXM"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "fA-gqyfjiQLO"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"Provide a comprehensive summary of the following text, highlighting the key points and main ideas. Make sure to capture the essential details while leaving out any irrelevant or extraneous information. Your summary should be detailed and informative, while still being concise and easy to understand. Avoid adding any external information or making assumptions beyond what is provided in the text.\"\n",
        "You can modify this prompt to fit your specific needs, but the key is to emphasize the importance of comprehensiveness, accuracy, and clarity in the summary.\"\"\"\n",
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
        "    SYSTEM_PROMPT = new_system_prompt\n",
        "    prompt_template =  SYSTEM_PROMPT + instruction\n",
        "    return prompt_template"
      ],
      "metadata": {
        "id": "lvp6AJfDiXpp"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"\"\"Provide a comprehensive summary of the following text, highlighting the key points and main ideas. Make sure to capture the essential details while leaving out any irrelevant or extraneous information. Your summary should be detailed and informative, while still being concise and easy to understand. Avoid adding any external information or making assumptions beyond what is provided in the text.\"\n",
        "You can modify this prompt to fit your specific needs, but the key is to emphasize the importance of comprehensiveness, accuracy, and clarity in the summary.\"\"\"\n",
        "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "get_prompt(instruction, sys_prompt)"
      ],
      "metadata": {
        "id": "39sqYk6sjxEO",
        "outputId": "52a7026e-0dac-4311-c634-ed9d832383b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Provide a comprehensive summary of the following text, highlighting the key points and main ideas. Make sure to capture the essential details while leaving out any irrelevant or extraneous information. Your summary should be detailed and informative, while still being concise and easy to understand. Avoid adding any external information or making assumptions beyond what is provided in the text.\"\\nYou can modify this prompt to fit your specific needs, but the key is to emphasize the importance of comprehensiveness, accuracy, and clarity in the summary.CONTEXT:/n/n {context}/n\\n\\nQuestion: {question}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = get_prompt(instruction, sys_prompt)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "dOCo039tjzwG"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": prompt}\n"
      ],
      "metadata": {
        "id": "EnOVb-PmkhcB"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n"
      ],
      "metadata": {
        "id": "gYClFRaSk0Eq"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import prompt\n",
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                       chain_type=\"stuff\",\n",
        "                                       retriever=retriever,\n",
        "                                       chain_type_kwargs=chain_type_kwargs,\n",
        "                                       return_source_documents=True)"
      ],
      "metadata": {
        "id": "ibaA3jAZkk1j"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    return wrap_text_preserve_newlines(llm_response['result'])\n",
        "    #print('\\n\\nSources:')\n",
        "    #for source in llm_response[\"source_documents\"]:\n",
        "        #print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "0bdvxuhUkm5q"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = []\n",
        "summarized_answer = []"
      ],
      "metadata": {
        "id": "hKMEiN--nXLd"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "for i in items:\n",
        "  if i != \"\":\n",
        "    query = i\n",
        "    llm_response = qa_chain(query)\n",
        "    #print(llm_response)\n",
        "    topic.append(i)\n",
        "    summarized_answer.append(llm_response['result'])"
      ],
      "metadata": {
        "id": "4sA54kvBm-uT"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic"
      ],
      "metadata": {
        "id": "bVIBHuBTnjmX",
        "outputId": "f8b0f387-e300-4a26-d377-8cfc67dc6f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1: \"Loss\"\\n- \"Property damage\"\\n- \"Financial loss\"\\n- \"Emotional loss\"',\n",
              " '2: \"Coverage\"\\n- \"Liability coverage\"\\n- \"Property coverage\"\\n- \"Comprehensive coverage\"',\n",
              " '3: \"Revised\"\\n- \"Updated laws and regulations\"\\n- \"Changes in policy\"\\n- \"Revised coverage options\"',\n",
              " '4: \"Settlement\"\\n- \"Insurance claim settlement\"\\n- \"Settlement agreement\"\\n- \"Settlement negotiations\"',\n",
              " '5: \"Cost\"\\n- \"Insurance cost\"\\n- \"Repair cost\"\\n- \"Replacement cost\"',\n",
              " '6: \"Structures\"\\n- \"Home structures\"\\n- \"Business structures\"\\n- \"Coverage for structures\"',\n",
              " '1: \"Loss\"\\n- \"Property damage\"\\n- \"Financial loss\"\\n- \"Emotional loss\"',\n",
              " '2: \"Coverage\"\\n- \"Liability coverage\"\\n- \"Property coverage\"\\n- \"Comprehensive coverage\"',\n",
              " '3: \"Revised\"\\n- \"Updated laws and regulations\"\\n- \"Changes in policy\"\\n- \"Revised coverage options\"',\n",
              " '4: \"Settlement\"\\n- \"Insurance claim settlement\"\\n- \"Settlement agreement\"\\n- \"Settlement negotiations\"',\n",
              " '5: \"Cost\"\\n- \"Insurance cost\"\\n- \"Repair cost\"\\n- \"Replacement cost\"',\n",
              " '6: \"Structures\"\\n- \"Home structures\"\\n- \"Business structures\"\\n- \"Coverage for structures\"']"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_answer"
      ],
      "metadata": {
        "id": "wvDfrWImpP8Z",
        "outputId": "e6713a81-7207-4e8f-b65b-6e2d2e84e24e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The text outlines various settlement options for different types of losses related to property damage, including actual cash value loss settlements for specific structures away from the residence premises, windstorm or hail losses to roof surfacing, and sinkhole collapse coverage. It also includes coverage for limited water backup, sump discharge or overflow, home day care, refrigerated property, special personal property, and additional insured individuals living away from the residence premises. The text also mentions coverage for owned motorized golf carts, functional replacement cost loss settlement, modified functional replacement cost loss settlement, and extended theft coverage for residence premises occasionally rented to others. The concept of \"loss\" is discussed in terms of property damage, financial loss, and emotional loss.',\n",
              " 'The text provides a list of various insurance coverages, including liability coverage, property coverage, and comprehensive coverage. It includes specific policies such as Utility Line Expense Coverage, Home Business Insurance Coverage, Additional Insured for Managers or Lessors of Premises Leased to an Insured, and others. The text also mentions new limited cannabis property coverage, limited theft coverage for dwellings under construction, increased insurance amounts for personal property in self-storage facilities, and other specialized coverages. The focus is on different types of insurance protections and exclusions related to liability, property, and comprehensive coverage.',\n",
              " 'The text outlines a series of policy changes related to definitions, coverage limits, and thresholds in motor vehicle liability and business definitions. The changes include revisions to the motor vehicle liability definition, addressing mineral rights in the business definition, increasing dollar thresholds, and adjusting special limits and other dollar thresholds. Additionally, there are changes regarding model or hobby aircraft and watercraft coverage, as well as updates to the coverage of personal property not including motor vehicles. These revisions reflect updated laws and regulations, aiming to provide clearer and more comprehensive coverage options for policyholders.',\n",
              " 'The text provides a list of various homeowners insurance forms related to settlement agreements and coverage options. These forms include coverage for personal property, other structures away from the residence premises, specific structures, windstorm or hail losses to roof surfacing, and additional insured household residents. The forms also cover ordinance or law increased coverage, multiple company insurance, actual cash value loss settlement, personal property replacement cost settlement, assisted living care coverage, and special loss settlement. The text emphasizes the importance of understanding the different settlement options and coverage details in homeowners insurance policies.',\n",
              " 'The text discusses the conditions under which insurance companies will settle losses related to property damage. If the cost to repair or replace the damaged property is less than 5% of the insurance amount on the building and less than $5,000, the loss will be settled regardless of whether the repair or replacement is complete. Additionally, the text mentions a broadening of coverage in terms of personal property replacement cost loss settlement. It also outlines that increased costs incurred to comply with ordinances or laws are not included in repair or replacement costs unless coverage is provided separately. Furthermore, it states that buildings covered under certain insurance policies will be paid at replacement cost without depreciation if the insurance amount is 80% or more of the full replacement cost before the loss occurred. The text emphasizes the importance of understanding the different costs involved in property damage claims, such as insurance, repair, and replacement costs.',\n",
              " 'The text discusses various revisions and new endorsements in homeowners insurance policies. Key changes include the introduction of a new optional endorsement for excluding specified structures from coverage to provide underwriting flexibility. This allows insurers to accept risks they might otherwise decline, such as dilapidated sheds or barns. Other revisions include updates to coverage for green upgrades, mechanical breakdowns, cosmetic damage exclusions for windstorm or hail, and increased limits for damage to property of others. Additionally, there are withdrawals of endorsements related to home-sharing host activities. The focus is on enhancing coverage options and flexibility for insurers in assessing risks related to different types of structures.',\n",
              " 'The text outlines various settlement options for different types of losses related to property damage, including actual cash value loss settlements for specific structures away from the residence premises, windstorm or hail losses to roof surfacing, and sinkhole collapse coverage. It also includes coverage for limited water backup, sump discharge or overflow, home day care, refrigerated property, special personal property, and additional insured individuals living away from the residence premises. The text also mentions exclusions for windstorm or hail, as well as coverage for owned motorized golf carts, functional replacement cost loss settlement, modified functional replacement cost loss settlement, and extended theft coverage for residence premises occasionally rented to others. The focus is on providing financial compensation for various types of property damage, with no mention of emotional loss.',\n",
              " 'The text provides a list of various insurance coverage options, including liability coverage, property coverage, and comprehensive coverage. It outlines specific policies such as Utility Line Expense Coverage, Home Business Insurance Coverage, Additional Insured for Managers or Lessors of Premises Leased to an Insured, and others. The text also mentions specific exclusions and exceptions related to personal injury, liquor liability, computer-related damage, and more. Additionally, it highlights new coverage options like Limited Cannabis Property Coverage, Green Upgrades Coverage, and Mechanical Breakdown Coverage. Overall, the text serves as a comprehensive guide to different insurance coverage options and exclusions available.',\n",
              " 'The text outlines various policy changes related to definitions, coverage limits, and thresholds in the context of motor vehicle liability and business definitions. The changes include revisions to the motor vehicle liability definition, addressing mineral rights in the business definition, increasing dollar thresholds, and adjusting special limits and other dollar thresholds. Additionally, there are updates regarding model or hobby aircraft and watercraft coverage, as well as revisions to the coverage of personal property, specifically motor vehicles. These changes reflect updated laws and regulations, aiming to provide clearer and more comprehensive coverage options for policyholders.',\n",
              " 'The text provides a list of various homeowners insurance forms related to settlement agreements and coverage options. These forms include coverage for personal property, other structures away from the residence premises, specific structures, windstorm or hail losses, and additional insured household residents. The forms also cover ordinance or law increased coverage, multiple company insurance, actual cash value loss settlement, and personal property replacement cost settlement. The text emphasizes the importance of settlement in insurance claims and negotiations, highlighting the different types of settlements available for homeowners insurance policies.',\n",
              " 'The text discusses the conditions for settling losses related to repair or replacement costs in insurance policies. If the cost to repair or replace the damaged property is less than 5% of the insurance amount on the building and less than $5,000, the loss will be settled regardless of whether the repair or replacement is complete. Additionally, if the cost to repair or replace the property is more than $1,000, the insurer will pay no more than the actual cash value until the repair or replacement is complete. The text also mentions a broadening of coverage and revisions to the Personal Property Replacement Cost Loss Settlement Endorsement. It clarifies that increased costs due to ordinance or law enforcement are not included in repair or replacement costs unless coverage is provided separately. Buildings covered under certain insurance policies are eligible for replacement cost coverage without depreciation deductions if the insurance amount is 80% or more of the full replacement cost before the loss.',\n",
              " 'The text discusses various revisions and new endorsements in homeowners insurance policies. Key changes include the introduction of a new optional endorsement for excluding specified structures from coverage to provide underwriting flexibility. This allows insurers to accept risks they might otherwise decline, such as dilapidated sheds or barns. Other updates include revised coverage for green upgrades, mechanical breakdowns, cosmetic damage exclusions for windstorm or hail, and increased limits for damage to property of others. Additionally, there are withdrawals of endorsements related to home-sharing host activities. The focus is on enhancing coverage options and flexibility for insurers in assessing risks related to different structures.']"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(process_llm_response(llm_response))"
      ],
      "metadata": {
        "id": "a_mW-HRipVe7",
        "outputId": "7589116c-c0da-499e-cb1b-3613d2866d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text discusses various revisions and new endorsements in homeowners insurance policies. Key changes\n",
            "include the introduction of a new optional endorsement for excluding specified structures from coverage to\n",
            "provide underwriting flexibility. This allows insurers to accept risks they might otherwise decline, such as\n",
            "dilapidated sheds or barns. Other revisions include updates to coverage for green upgrades, mechanical\n",
            "breakdowns, cosmetic damage exclusions for windstorm or hail, and increased limits for damage to property of\n",
            "others. Additionally, there are withdrawals of endorsements related to home-sharing host activities. The\n",
            "changes aim to enhance coverage and liability options for policyholders, offering a choice between property\n",
            "coverage only or a combination of coverage and liability.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "id": "k5BALJpZp3L8",
        "outputId": "57a243f1-79ae-49b8-f19d-e9d40a9f8637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '1: \"Loss\"\\n- \"Property damage\"\\n- \"Financial loss\"\\n- \"Emotional loss\"',\n",
              " 'result': 'The text outlines various settlement options for different types of losses related to property damage, including actual cash value loss settlements for specific structures away from the residence premises, windstorm or hail losses to roof surfacing, and limited water backup and sump discharge coverage. It also includes coverage for sinkhole collapse, special personal property coverage, and additional insured coverage for students living away from the residence premises. The text also mentions coverage for owned motorized golf carts, functional replacement cost loss settlement, and extended theft coverage for residence premises occasionally rented to others. The concept of \"loss\" is discussed in terms of property damage, financial loss, and emotional loss.',\n",
              " 'source_documents': [Document(page_content='Residence Premises  - Actual Cash Value Loss  \\nSettlemen t \\nHO 04 92 03 22  02 17  Specific Structures Away From The Residence \\nPremises - Actual Cash Value Loss  Settleme nt \\nHO 04 93  03 22  04 16  Actual Cash Value Loss Set tlement For \\nWind storm O r Hail  Losses  To Roo f Surfacing  \\nHO 04 94 03 22  10 00  Windstorm Or Hail Exclusion \\nHO 04 9 5 03 22  01 14  Limited Water Back -Up And Sump Di scharge O r \\nOverflow Coverage  \\nHO 04 97 03  22 05 11  Limited Home Day Care Coverage  \\nHO 04 9 8 03 22  05 11  Refriger ated Propert y Coverage  \\nHO 04 99 03 22  10 00  Sinkhole Collapse Coverage  \\nHO 05 24 03 22 05 11  Special Per sonal Property Coverage  \\nHO 05 27 03 22  05 11  Additional Insured - Student Living Away From \\nThe Residence Premises'),\n",
              "  Document(page_content='Residence Premises  - Actual Cash Value Loss  \\nSettlemen t \\nHO 04 92 03 22  02 17  Specific Structures Away From The Residence \\nPremises - Actual Cash Value Loss  Settleme nt \\nHO 04 93  03 22  04 16  Actual Cash Value Loss Set tlement For \\nWind storm O r Hail  Losses  To Roo f Surfacing  \\nHO 04 94 03 22  10 00  Windstorm Or Hail Exclusion \\nHO 04 9 5 03 22  01 14  Limited Water Back -Up And Sump Di scharge O r \\nOverflow Coverage  \\nHO 04 97 03  22 05 11  Limited Home Day Care Coverage  \\nHO 04 9 8 03 22  05 11  Refriger ated Propert y Coverage  \\nHO 04 99 03 22  10 00  Sinkhole Collapse Coverage  \\nHO 05 24 03 22 05 11  Special Per sonal Property Coverage  \\nHO 05 27 03 22  05 11  Additional Insured - Student Living Away From \\nThe Residence Premises'),\n",
              "  Document(page_content='Residence Premises  - Actual Cash Value Loss  \\nSettlemen t \\nHO 04 92 03 22  02 17  Specific Structures Away From The Residence \\nPremises - Actual Cash Value Loss  Settleme nt \\nHO 04 93  03 22  04 16  Actual Cash Value Loss Set tlement For \\nWind storm O r Hail  Losses  To Roo f Surfacing  \\nHO 04 94 03 22  10 00  Windstorm Or Hail Exclusion \\nHO 04 9 5 03 22  01 14  Limited Water Back -Up And Sump Di scharge O r \\nOverflow Coverage  \\nHO 04 97 03  22 05 11  Limited Home Day Care Coverage  \\nHO 04 9 8 03 22  05 11  Refriger ated Propert y Coverage  \\nHO 04 99 03 22  10 00  Sinkhole Collapse Coverage  \\nHO 05 24 03 22 05 11  Special Per sonal Property Coverage  \\nHO 05 27 03 22  05 11  Additional Insured - Student Living Away From \\nThe Residence Premises'),\n",
              "  Document(page_content='Residence Premises  - Actual Cash Value Loss  \\nSettlemen t \\nHO 04 92 03 22  02 17  Specific Structures Away From The Residence \\nPremises - Actual Cash Value Loss  Settleme nt \\nHO 04 93  03 22  04 16  Actual Cash Value Loss Set tlement For \\nWind storm O r Hail  Losses  To Roo f Surfacing  \\nHO 04 94 03 22  10 00  Windstorm Or Hail Exclusion \\nHO 04 9 5 03 22  01 14  Limited Water Back -Up And Sump Di scharge O r \\nOverflow Coverage  \\nHO 04 97 03  22 05 11  Limited Home Day Care Coverage  \\nHO 04 9 8 03 22  05 11  Refriger ated Propert y Coverage  \\nHO 04 99 03 22  10 00  Sinkhole Collapse Coverage  \\nHO 05 24 03 22 05 11  Special Per sonal Property Coverage  \\nHO 05 27 03 22  05 11  Additional Insured - Student Living Away From \\nThe Residence Premises'),\n",
              "  Document(page_content='Premises – Actual Cash Val ue Loss Settlement  \\n\\uf0a8 HO 04 92, Speci fic Struc tures Away From The R esiden ce Premises – Actua l \\nCash Value  Loss Set tlement \\n\\uf0a8 HO 04 93 , Actual Cash Value Loss Settleme nt for  Windstorm or Hail Losses \\nto Roof Surf acing \\n\\uf0a8 HO 04 94,  Winds torm or Hail Exclusion  \\n\\uf0a8 HO 04 95,  Limited  Wate r Back -up and Sump Di scharge o r Over flow \\nCover age \\n\\uf0a8 HO 04 97, Limited H ome Day Care Covera ge \\n\\uf0a8 HO 04 98, Refri gerated  Property Coverage  \\n\\uf0a8 HO 04 99,  Sinkhole C ollapse Coverage  \\n\\uf0a8 HO 05 24, Special Per sonal Property Coverage  \\n\\uf0a8 HO 05 27, Additional Insured – Stude nt Living Away From The Res idence \\nPremises  \\n\\uf0a8 HO 0 5 28,  Owned Moto rized Golf Cart Phy sical Loss C overage  \\n\\uf0a8 HO 05  30, Functio nal Replacement Cost  Loss Settlem ent \\n\\uf0a8 HO 05 31, Modified Fu nctional  Replacemen t Cost Loss Settlement  \\n\\uf0a8 HO 05 41,  Extended Theft Covera ge For Resid ence Premises Occasio nally \\nRented to  Othe rs')]}"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response['result']"
      ],
      "metadata": {
        "id": "hsdKXcVnqeLL",
        "outputId": "c801cc32-c1d5-4446-9a78-2fc1b6fd0ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The text outlines various settlement options for different types of losses related to property damage, including actual cash value loss settlements for specific structures away from the residence premises, windstorm or hail losses to roof surfacing, and limited water backup and sump discharge coverage. It also includes coverage for sinkhole collapse, special personal property coverage, and additional insured coverage for students living away from the residence premises. The text also mentions coverage for owned motorized golf carts, functional replacement cost loss settlement, and extended theft coverage for residence premises occasionally rented to others. The concept of \"loss\" is discussed in terms of property damage, financial loss, and emotional loss.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZg5RmRCqiIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}